{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\" size=7>Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code replicates the braingeneers [deepspike dashboad](http://braingeneers.gi.ucsc.edu/dashboard/deepspike). The source code that david parks wrote can be [found here](https://github.com/braingeneers/dashboard/blob/master/apps/app_deepspike.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## <font color=\"orange\"> Errors to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color=\"red\">There was an error when:</font>\n",
    "``` python\n",
    "data_files_basepath='s3://braingeneers/personal/dfparks/deepspike/dataset_zenodo/'\n",
    "```\n",
    "**fix this!**\n",
    "```\n",
    "NotFoundError: Object s3://braingeneers/personal/dfparks/deepspike/dataset_zenodo/recordings_36cells_four-tetrodes_30.0_10.0uV_20-06-2019_14_48.h5 does not exist\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as ipw\n",
    "import boto3 # look up what this package is\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Main dataset locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws --endpoint https://s3.nautilus.optiputer.net s3 cp s3://braingeneers/personal/dfparks/deepspike/dataset_zenodo/recordings_36cells_four-tetrodes_30.0_10.0uV_20-06-2019_14_48.h5  .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download call results locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws --endpoint https://s3.nautilus.optiputer.net s3 cp s3://braingeneers/personal/dfparks/deepspike/results/spikesortv2/zenodo_results.call.json .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color=\"gray\">Helper Class: NeuralDataReaderZenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Raw data reader for Zenodo data. Will be replaced when I move to a more generic dataset format.\n",
    "class NeuralDataReaderZenodo:\n",
    "    FILE_CACHE = {}\n",
    "\n",
    "    def __init__(self, data_files: (tuple, list), data_files_basepath: str):\n",
    "        self.data_files = data_files\n",
    "        self.data_files_basepath = data_files_basepath\n",
    "        self._data_files_sample_counts = None  # lazy evaluation\n",
    "        self._data_files_sample_counts_cumsum = None  # lazy evaluation\n",
    "\n",
    "    \"\"\" Reads neural data from the Zenodo HDF5 file format. \"\"\"\n",
    "    def read_data(self, global_neural_offset: int, read_length: int, channels: (list, tuple) = None):\n",
    "        data_file_index, local_neural_offset = self.resolve_local_neural_offset(global_neural_offset)\n",
    "        data_file = self.data_files[data_file_index]\n",
    "        if data_file_index not in NeuralDataReaderZenodo.FILE_CACHE:\n",
    "            NeuralDataReaderZenodo.FILE_CACHE[data_file_index] = \\\n",
    "                tf.io.gfile.GFile(os.path.join(self.data_files_basepath, data_file), mode='rb')\n",
    "\n",
    "        f = NeuralDataReaderZenodo.FILE_CACHE[data_file_index]\n",
    "        h5f = h5py.File(f, 'r')\n",
    "\n",
    "        channels_ixs = np.arange(h5f['recordings'].shape[0]) if channels is None else channels\n",
    "        data = h5f['recordings'][channels_ixs, local_neural_offset:local_neural_offset + read_length]\n",
    "\n",
    "        return data.T.astype(np.float32)\n",
    "\n",
    "    def data_files_sample_counts(self):\n",
    "        if self._data_files_sample_counts is None:\n",
    "            self._data_files_sample_counts = []\n",
    "            for df in self.data_files:\n",
    "                with tf.io.gfile.GFile(os.path.join(self.data_files_basepath, df), mode='rb') as f:\n",
    "                    h5f = h5py.File(f, 'r')\n",
    "                    self._data_files_sample_counts.append(h5f['recordings'].shape[1])\n",
    "\n",
    "        return self._data_files_sample_counts\n",
    "\n",
    "    def resolve_local_neural_offset(self, global_neural_offset):\n",
    "        \"\"\" Resolves a global_neural_offset to a data_files index and local neural_offset into that file \"\"\"\n",
    "        if self._data_files_sample_counts_cumsum is None:\n",
    "            self._data_files_sample_counts_cumsum = np.cumsum(self.data_files_sample_counts())\n",
    "\n",
    "        ix = np.searchsorted(self._data_files_sample_counts_cumsum, global_neural_offset, side='right')\n",
    "        assert 0 <= ix < len(self.data_files)\n",
    "        lno = global_neural_offset - self._data_files_sample_counts_cumsum[ix - 1] if ix > 0 else global_neural_offset\n",
    "\n",
    "        return ix, lno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"gray\">Helper Function: compute_call_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_call_spikes(time_offset, channel_number, data_calls):\n",
    "    called_spikes = [\n",
    "        c for c in data_calls\n",
    "        if time_offset - GRAPH_WIDTH < c['spike_center_ix'] < time_offset + GRAPH_WIDTH \\\n",
    "        and c['channel'] == channel_number\n",
    "    ]\n",
    "    return called_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `called_spikes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using david's code to create the `called_spikes` variable that is fed into the <font color=\"blue\">update_lfp_graph</font> function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"zenodo_results.call.json\") as f:\n",
    "    data_calls = json.load(f)\n",
    "called_spikes = compute_call_spikes(time_offset, channel_number, data_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import apps.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_calls = json.load(\"zenodo_results.call.json\")\n",
    "#data_calls = json.loads( utils.read_s3_bytes(\n",
    "#        bucket='braingeneers', key='personal/dfparks/deepspike/results/spikesortv2/zenodo_results.call.json'\n",
    "#    ).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_calls = json.load(\"zenodo_results.call.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update_lfp_graph <small>(line 446)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=\"green\"> widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_channel = ipw.IntSlider(value=10, min=0,max=30,description='Channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Time Offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_time_offset = ipw.IntSlider(value=1, min=0,max=10,description='Time Offset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_time_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Davids Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">There was an error when:</font>\n",
    "``` python\n",
    "data_files_basepath='s3://braingeneers/personal/dfparks/deepspike/dataset_zenodo/'\n",
    "```\n",
    "**fix this!**\n",
    "```\n",
    "NotFoundError: Object s3://braingeneers/personal/dfparks/deepspike/dataset_zenodo/recordings_36cells_four-tetrodes_30.0_10.0uV_20-06-2019_14_48.h5 does not exist\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value from widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_number_int = w_channel.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_offset = w_time_offset.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Beginning variables to set: (line 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 500  # this needs to be somewhere standardized as well, necessary for converting [-1, +1] back\n",
    "GRAPH_WIDTH = 1000\n",
    "KERNEL_SIZE = int(WINDOW_SIZE * 0.4) + 1  # size of the median filter kernel\n",
    "s3client = boto3.client('s3', endpoint_url=\"https://s3.nautilus.optiputer.net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set class for reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = NeuralDataReaderZenodo(\n",
    "    data_files=['recordings_36cells_four-tetrodes_30.0_10.0uV_20-06-2019_14_48.h5'],\n",
    "    data_files_basepath=''\n",
    "    #data_files_basepath='s3://braingeneers/personal/dfparks/deepspike/dataset_zenodo/',\n",
    "    # data_files_basepath='/dashboard/tmp/app_deepspike/zenodo/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw data, pad when the graph would extend beyond either side of the available data\n",
    "global_neural_offset = max(0, time_offset - int(GRAPH_WIDTH//2))\n",
    "pad_left = abs(min(0, time_offset - int(GRAPH_WIDTH//2)))\n",
    "pad_right = abs(min(0, sum(reader.data_files_sample_counts()) - time_offset - GRAPH_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "read_length = GRAPH_WIDTH - pad_left + pad_right\n",
    "data_local = reader.read_data(global_neural_offset=global_neural_offset,\n",
    "                              read_length=read_length, channels=[channel_number_int])\n",
    "data_local = np.squeeze(data_local)\n",
    "data_local = np.pad(data_local, (pad_left, pad_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(data_local) == GRAPH_WIDTH\n",
    "x_data = np.arange(time_offset - int(GRAPH_WIDTH//2), time_offset + int(GRAPH_WIDTH//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = []\n",
    "for c in called_spikes:\n",
    "    w_npy = np.squeeze(waveform_distribution().generate_waveform(*c['parameters']))\n",
    "    ix_start = int(c['spike_center_ix'] - (w_npy.shape[0] // 2))\n",
    "    x = np.arange(ix_start, ix_start + w_npy.shape[0])\n",
    "    waveforms.append((x, w_npy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = dict(\n",
    "    data=[\n",
    "        dict(\n",
    "            x=x_data,\n",
    "            y=data_local,\n",
    "            name='Raw LFP Data',\n",
    "            line=dict(color='rgb(55, 83, 109)', width=1),\n",
    "        )\n",
    "    ] + [\n",
    "        dict(\n",
    "            x=wfx,\n",
    "            y=wfy,\n",
    "            name='Predicted waveform',\n",
    "            showlegend=False if count > 0 else True,  # enable only for the first\n",
    "            line=dict(color='rgba(255, 0, 0, 0.65)', width=4)\n",
    "        )\n",
    "        for count, (wfx, wfy) in enumerate(waveforms)\n",
    "    ],\n",
    "    layout=dict(\n",
    "        xaxis=dict(\n",
    "            range=(time_offset - int(GRAPH_WIDTH//2), time_offset + int(GRAPH_WIDTH//2)),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='LFP',\n",
    "        ),\n",
    "        autosize=True,\n",
    "        hovermode=\"closest\",\n",
    "        plot_bgcolor=\"#F9F9F9\",\n",
    "        paper_bgcolor=\"#F9F9F9\",\n",
    "        title='LFP Data',\n",
    "        showlegend=True,\n",
    "        legend=dict(x=0, y=1.0),\n",
    "        shapes=[\n",
    "            dict(\n",
    "                type='rect',\n",
    "                xref='x',\n",
    "                yref='paper',\n",
    "                x0=c['spike_center_ix'] - x, x1=c['spike_center_ix'] + x,\n",
    "                y0=0, y1=1,\n",
    "                fillcolor='Green',\n",
    "                opacity=0.07,\n",
    "                layer='above',\n",
    "                line=dict(width=0),\n",
    "            )\n",
    "            for x in [50, 40, 30, 20, 10]\n",
    "            for c in called_spikes\n",
    "        ],\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
